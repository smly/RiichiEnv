grp:
  train_data:
    - /data/workspace/riichienv/datasets/train_grp.pq
    - /data/workspace/riichienv/datasets/train_grp_2024.pq
  val_data: /data/workspace/riichienv/datasets/val_grp.pq
  output: /data/workspace/riichienv/baseline/grp_model.pth
  device: cuda
  batch_size: 128
  num_workers: 12
  num_epochs: 10
  lr: 5e-4
  input_dim: 20

cql:
  data_glob: "/data/mjsoul/mahjong_game_record_4p_thr_202[45]*/*.bin.xz"
  grp_model: /data/workspace/riichienv/baseline/grp_model.pth
  output: /data/workspace/riichienv/baseline/cql_model.pth
  device: cuda
  batch_size: 128
  lr: 5e-4
  alpha: 5.0
  gamma: 1.0
  num_epochs: 10
  num_workers: 12
  limit: 2000000
  pts_weight: [6.0, 4.0, 2.0, 0.0]
  weight_decay: 0.1
  aux_weight: 0.2
  wandb_entity: smly
  wandb_project: riichienv-offline
  model_class: riichienv_ml.models.cql_model.QNetwork
  dataset_class: riichienv_ml.data.cql_dataset.MCDataset
  model:
    in_channels: 74
    num_blocks: 16
    conv_channels: 192
    fc_dim: 512
    num_actions: 82
    aux_dims: 4

online:
  load_model: /data/workspace/riichienv/baseline/cql_model.pth
  device: cuda
  model_class: riichienv_ml.models.cql_model.QNetwork
  num_workers: 12
  num_steps: 1000000
  batch_size: 512
  lr: 1e-4
  lr_min: 1e-5
  max_grad_norm: 5.0           # prevent catastrophic gradient spikes during fine-tuning
  alpha_cql_init: 0.5            # Moderate CQL: Q-value regularization
  alpha_cql_final: 0.1           # Decay to allow more policy freedom
  alpha_kl: 0.0                  # No KL: baseline data + CQL sufficient
  collect_hero_only: false        # All 4 players for volume + implicit regularization
  entropy_coef: 0.01            # mild entropy bonus as additional collapse safeguard
  target_update_freq: 2000      # unused (MC returns), kept for config compat

  exploration: boltzmann
  boltzmann_epsilon: 0.02           # 2% Boltzmann, 98% greedy — high signal-to-noise
  boltzmann_temp_start: 0.1         # low temp: near-greedy sampling when exploring
  boltzmann_temp_final: 0.05        # even more greedy late
  top_p: 0.9
  capacity: 500000            # larger buffer to preserve CQL-quality data longer
  # GRP reward shaping (per-kyoku reward)
  grp_model: /data/workspace/riichienv/baseline/grp_model.pth
  pts_weight: [6.0, 4.0, 2.0, 0.0]
  weight_decay: 0.1
  aux_weight: 0.2
  eval_interval: 5000
  eval_episodes: 400
  weight_sync_freq: 10
  worker_device: cuda
  gpu_per_worker: 0.08
  num_envs_per_worker: 16
  gamma: 0.97                         # Decayed MC returns: R * γ^(T-t-1) for temporal credit
  checkpoint_dir: /data/workspace/riichienv/baseline/checkpoints
  wandb_project: riichienv-online
  model:
    in_channels: 74
    num_blocks: 16
    conv_channels: 192
    fc_dim: 512
    num_actions: 82
    aux_dims: 4
